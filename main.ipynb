{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pprint\n",
    "import time\n",
    "from collections.abc import Collection\n",
    "from enum import Enum\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpotifyAPI:\n",
    "    class SpotifyAPIError(Exception):\n",
    "        def __init__(self, error_type: str, error_description: str):\n",
    "            self.error_type = error_type\n",
    "            self.error_description = error_description\n",
    "            super().__init__(f\"{self.error_type}: {self.error_description}\")\n",
    "\n",
    "    class AccessToken:\n",
    "        def __init__(self, client_id: str, client_secret: str):\n",
    "            self._client_id = client_id\n",
    "            self._client_secret = client_secret\n",
    "            self._token, self._expires_at = self.get_auth_token()\n",
    "            self._header = {\"Authorization\": f\"Bearer {self._token}\"}\n",
    "\n",
    "        def get_auth_token(self) -> tuple[str, float]:\n",
    "            url = \"https://accounts.spotify.com/api/token\"\n",
    "            header = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "            payload = {\n",
    "                \"grant_type\": \"client_credentials\",\n",
    "                \"client_id\": self._client_id,\n",
    "                \"client_secret\": self._client_secret,\n",
    "            }\n",
    "            response = requests.post(url=url, headers=header, data=payload)\n",
    "            # TODO: Handle HTTP error and Authentication Error\n",
    "            acquired_at = time.time()\n",
    "            logger.info(f\"Token expires at {response.json()}\")\n",
    "            expire_at = acquired_at + float(response.json()[\"expires_in\"])\n",
    "            return response.json()[\"access_token\"], expire_at\n",
    "\n",
    "        @property\n",
    "        def token(self) -> str:\n",
    "            # TODO: Add logging for token refresh\n",
    "            if time.time() >= self._expires_at:\n",
    "                logger.info(\"Refreshing Spotify API token\")\n",
    "                self._token, self._expires_at = self.get_auth_token()\n",
    "            return self._token\n",
    "\n",
    "        @property\n",
    "        def header(self) -> dict:\n",
    "            return {\"Authorization\": f\"Bearer {self.token}\"}\n",
    "\n",
    "    def __init__(self, client_id, client_secret):\n",
    "        self.token = self.AccessToken(client_id, client_secret)\n",
    "\n",
    "    def get_track(self, track_id: str) -> dict:\n",
    "        url = f\"https://api.spotify.com/v1/tracks/{track_id}\"\n",
    "        response = requests.get(url=url, headers=self.token.header)\n",
    "        return response.json()\n",
    "\n",
    "    def get_tracks(self, track_ids: Collection[str]) -> dict:\n",
    "        if len(track_ids) > 50:\n",
    "            raise ValueError(\"Maximum 50 tracks per request\")\n",
    "        url = f\"https://api.spotify.com/v1/tracks\"\n",
    "        payload = {\"ids\": \",\".join(track_ids)}\n",
    "        response = requests.get(url=url, headers=self.token.header, params=payload)\n",
    "        return response.json()\n",
    "\n",
    "    def get_track_features(self, track_id: str) -> dict:\n",
    "        url = f\"https://api.spotify.com/v1/audio-features/{track_id}\"\n",
    "        response = requests.get(url=url, headers=self.token.header)\n",
    "        return response.json()\n",
    "\n",
    "    def get_tracks_features(self, track_ids: Collection[str]) -> dict:\n",
    "        if len(track_ids) > 50:\n",
    "            raise ValueError(\"Maximum 50 tracks per request\")\n",
    "        url = f\"https://api.spotify.com/v1/audio-features\"\n",
    "        payload = {\"ids\": \",\".join(track_ids)}\n",
    "        response = requests.get(url=url, headers=self.token.header, params=payload)\n",
    "        return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tracks(df: pd.DataFrame, max_tracks: int = 100, path: str = \"data/tracks\"):\n",
    "    logger.info(f\"Getting audio data of the first {max_tracks} tracks...\")\n",
    "    \n",
    "    api = SpotifyAPI(os.getenv(\"SPOTIFY_CLIENT_ID\"), os.getenv(\"SPOTIFY_CLIENT_SECRET\"))\n",
    "    songs = df[\"track_id\"].head(max_tracks)\n",
    "\n",
    "    existing_songs = {f.removesuffix(\".mp3\") for f in os.listdir(path)}\n",
    "    logger.debug(f\"Found {len(existing_songs)} existing tracks\")\n",
    "\n",
    "    with open(f\"{path}/tracks_data.csv\", \"a+\") as f:\n",
    "        try:\n",
    "            track_data = json.load(f)\n",
    "        except json.decoder.JSONDecodeError:\n",
    "            logger.info(\"No existing track data found, or file is corrupted\")\n",
    "            track_data = {}\n",
    "\n",
    "    num_splits = (len(songs) // 50) + (len(songs) % 50 > 0)\n",
    "\n",
    "    for song_batch in np.array_split(songs, num_splits):\n",
    "        try:\n",
    "            logger.debug(f\"Downloading audio features for track {song_batch.tolist()}\")\n",
    "            song_batch = set(song_batch.tolist()) - existing_songs\n",
    "            tracks: list = api.get_tracks(song_batch)[\"tracks\"]\n",
    "\n",
    "            for track in tracks:\n",
    "                track_data[track[\"id\"]] = track\n",
    "                preview_url = track[\"preview_url\"]\n",
    "\n",
    "                if preview_url is None:\n",
    "                    logger.debug(\n",
    "                        f\"Skipping {track['id']} for missing preview url\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                response = requests.get(track[\"preview_url\"])\n",
    "                with open(f\"{path}/{track['id']}.mp3\", \"wb\") as f:\n",
    "                    f.write(response.content)\n",
    "\n",
    "                existing_songs.add(track[\"id\"])\n",
    "                time.sleep(0.1)\n",
    "            time.sleep(3)\n",
    "\n",
    "        except SpotifyAPI.SpotifyAPIError as e:\n",
    "            logger.error(e)\n",
    "            continue\n",
    "\n",
    "    with open(\"data/tracks_data.csv\", \"w\") as f:\n",
    "        json.dump(track_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path: str = \"data/dataset.csv\") -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_visualization(df: pd.DataFrame) -> None:\n",
    "    # pp.pprint(df.columns.to_list())\n",
    "    df = df.sort_values(by=\"popularity\", ascending=False)\n",
    "\n",
    "    ax = sns.displot(data=df, x=\"popularity\", kde=True, aspect=2)\n",
    "    ax.set(title=\"Popularity Distribution\", xlabel=\"Popularity\", ylabel=\"Count\")\n",
    "\n",
    "    ax = sns.catplot(data=df, x=\"track_genre\", y=\"popularity\", kind=\"box\", aspect=4, width=0.8)\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "\n",
    "    # Popular songs tents to have higher danceability and enrergy\n",
    "    ax = sns.relplot(data=df, x=\"popularity\", y=\"danceability\", aspect=2, s=10, hue=\"popularity_category\", legend=False)\n",
    "    ax.set(\n",
    "        title=\"Relationship plot between Popularity and Danceability \",\n",
    "        xlabel=\"Popularity\",\n",
    "        ylabel=\"Danceability\",\n",
    "    )\n",
    "    \n",
    "    ax = sns.relplot(data=df, x=\"popularity\", y=\"energy\", aspect=2, s=10, hue=\"popularity_category\", legend=False)\n",
    "    ax.set(\n",
    "        title=\"Relationship plot between Popularity and Energy \",\n",
    "        xlabel=\"Popularity\",\n",
    "        ylabel=\"Energy\",\n",
    "    )\n",
    "    \n",
    "    # Popularity of songs with higher speechiness tents to sit around 20\n",
    "    ax = sns.relplot(data=df, x=\"popularity\", y=\"speechiness\", aspect=2, s=10, hue=\"popularity_category\", legend=False)\n",
    "    ax.set(\n",
    "        title=\"Relationship plot between Popularity and Speechiness \",\n",
    "        xlabel=\"Popularity\",\n",
    "        ylabel=\"Speechiness\",\n",
    "    )\n",
    "\n",
    "    # Songs with high or low popularity tends to have lower instrumentalness\n",
    "    ax = sns.relplot(data=df, x=\"popularity\", y=\"liveness\", aspect=2, s=10, hue=\"popularity_category\", legend=False)\n",
    "    ax.set(\n",
    "        title=\"Relationship plot between Popularity and Liveness \",\n",
    "        xlabel=\"Popularity\",\n",
    "        ylabel=\"Liveness\",\n",
    "    )\n",
    "\n",
    "    # Features that does not show significant relationship\n",
    "    # ax = sns.relplot(data=df, x=\"popularity\", y=\"tempo\", aspect=2, s=10)\n",
    "    # ax = sns.relplot(data=df, x=\"popularity\", y=\"acousticness\", aspect=2, s=10)\n",
    "    # ax = sns.relplot(data=df, x=\"popularity\", y=\"instrumentalness\", aspect=2, s=10)\n",
    "    # ax = sns.relplot(data=df, x=\"popularity\", y=\"valence\", aspect=2, s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mode(Enum):\n",
    "    FULL = 0\n",
    "    REDUCED_ACOUSTIC = 1\n",
    "    REDUCED = 2\n",
    "\n",
    "\n",
    "def preprocessing(\n",
    "    df: pd.DataFrame,\n",
    "    use_title_track=True,\n",
    "    acoustic_features: dict | None = None,\n",
    "    mode: Mode = Mode.REDUCED_ACOUSTIC,\n",
    ") -> tuple:\n",
    "    if mode == Mode.REDUCED_ACOUSTIC or mode == Mode.REDUCED:\n",
    "        df[\"acoustic_feature\"] = df.apply(\n",
    "            lambda row: acoustic_features.get(row[\"track_id\"], None), axis=1\n",
    "        )\n",
    "        df = df.dropna()\n",
    "        acoustic_features = np.stack(df[\"acoustic_feature\"], axis=0)\n",
    "        df = df.drop(columns=[\"acoustic_feature\"])\n",
    "    X = df.drop(columns=[\"popularity\"])\n",
    "    y = df[\"popularity\"]\n",
    "\n",
    "    # Feature Engineering\n",
    "    if use_title_track:\n",
    "        df[\"is_title_track\"] = df[\"track_name\"].str.lower() == df[\"artists\"].str.lower()\n",
    "\n",
    "    # Encoding\n",
    "    genre_encoder = LabelEncoder()\n",
    "    genre_encoder.fit(X[\"track_genre\"])\n",
    "    X[\"track_genre\"] = genre_encoder.transform(X[\"track_genre\"])\n",
    "\n",
    "    # Process with missing/extreme values\n",
    "    ...\n",
    "\n",
    "    # Drop\n",
    "    X = X.drop(columns=[\"track_id\", \"artists\", \"album_name\", \"track_name\"])\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test, acoustic_train, acoustic_test = train_test_split(\n",
    "        X, y, acoustic_features, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Normalization: duration_ms\n",
    "    # For MLPRegressor, normalization is required\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(X_train[[\"duration_ms\", \"instrumentalness\"]])\n",
    "    X_train[[\"duration_ms\", \"instrumentalness\"]] = scaler.transform(\n",
    "        X_train[[\"duration_ms\", \"instrumentalness\"]]\n",
    "    )\n",
    "    X_test[[\"duration_ms\", \"instrumentalness\"]] = scaler.transform(\n",
    "        X_test[[\"duration_ms\", \"instrumentalness\"]]\n",
    "    )\n",
    "\n",
    "    if mode == Mode.REDUCED_ACOUSTIC:\n",
    "        X_train = np.concatenate((X_train, acoustic_train), axis=1)\n",
    "        X_test = np.concatenate((X_test, acoustic_test), axis=1)\n",
    "\n",
    "    return X_train, X_test, y_train.to_numpy(), y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acoustic_feature(df: pd.DataFrame, path: str = \"data/tracks\") -> pd.DataFrame:\n",
    "    \"\"\"Extract features from audio files and add them to the dataframe\n",
    "    * Mel-Frequency Cepstral Coefficients(MFCC)\n",
    "    * Spectral centroid\n",
    "    * Spectral flatness\n",
    "    * Zero crossings\n",
    "\n",
    "    Keyword arguments:\n",
    "    df -- Source dataframe\n",
    "    path -- Path to the audio files\n",
    "    Return: Dataframe with extracted acoustic features\n",
    "    \"\"\"\n",
    "    tracks = os.listdir(path)\n",
    "\n",
    "    # df[\"acoustic_features\"] = df.apply(lambda r: np.zeros((1,)), axis=1)\n",
    "\n",
    "    acoustic_features = {}\n",
    "\n",
    "    for tracks in tqdm(tracks):\n",
    "        if tracks.endswith(\".mp3\"):\n",
    "            track_id = tracks.split(\".\")[0]\n",
    "            track_path = f\"{path}/{tracks}\"\n",
    "            y, sr = librosa.load(track_path)\n",
    "            spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "            spectral_flatness = librosa.feature.spectral_flatness(y=y)\n",
    "            zero_crossings = librosa.feature.zero_crossing_rate(y=y)\n",
    "            acoustic_feature = np.concatenate(\n",
    "                (spectral_centroid, spectral_flatness, zero_crossings), axis=1\n",
    "            ).squeeze()\n",
    "            acoustic_features[track_id] = acoustic_feature\n",
    "\n",
    "    return acoustic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_mlp(X, y):\n",
    "    model = MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=500)\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_mlp_cls(X, y):\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=500)\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_xgb(X, y) -> XGBRegressor:\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.01,\n",
    "        n_jobs=4,\n",
    "        random_state=42,\n",
    "        # device=\"cuda\",\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_xgb_cls(X, y) -> XGBClassifier:\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.01,\n",
    "        n_jobs=4,\n",
    "        random_state=42,\n",
    "        # device=\"cuda\",\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_random_forest(X, y) -> RandomForestClassifier:\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=10, n_jobs=4, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = y_pred.clip(0, 100)\n",
    "    y_pred = y_pred.astype(int)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    remove_zero_popularity = True\n",
    "    reduce_popularity = True\n",
    "    visualization = True\n",
    "    use_acoustic_features = False\n",
    "\n",
    "    mode = Mode.REDUCED\n",
    "\n",
    "    df = read_data()\n",
    "    \n",
    "    labels=[\"unpopular\", \"intermediate\", \"popular\", \"highly_popular\"]\n",
    "\n",
    "    if remove_zero_popularity:\n",
    "        df = df[df[\"popularity\"] > 0]\n",
    "\n",
    "    if reduce_popularity:\n",
    "        if not remove_zero_popularity:\n",
    "            raise ValueError(\"remove_zero_popularity must be True if reduce_popularity is True\")\n",
    "\n",
    "        # NOTE: The SettingWithCopyWarning should be ignored\n",
    "        df[\"popularity_category\"] = pd.qcut(df[\"popularity\"], 4, labels=False)\n",
    "\n",
    "        # bins = df[[\"popularity\"]].describe().loc[[\"25%\", \"50%\", \"75%\"]][\"popularity\"].to_list()\n",
    "        # df[\"popularity\"] = pd.cut(\n",
    "        #     df[\"popularity\"],\n",
    "        #     bins=[0,] + bins + [100,],\n",
    "        #     labels=[0, 1, 2, 3],\n",
    "        #     # labels=[\"unpopular\", \"intermediate\", \"popular\", \"highly_popular\"],\n",
    "        # )\n",
    "\n",
    "    if visualization:\n",
    "        data_visualization(df)\n",
    "\n",
    "    match mode:\n",
    "        case Mode.FULL:\n",
    "            pass\n",
    "        case Mode.REDUCED_ACOUSTIC | Mode.REDUCED:\n",
    "            logger.info(\"Downloading acoustic features...\")\n",
    "            # download_tracks(df, max_tracks=10000, path=\"data/tracks\")\n",
    "            logger.info(\"Building acoustic features...\")\n",
    "            acoustic_features = get_acoustic_feature(df)\n",
    "\n",
    "    if reduce_popularity:\n",
    "        df[\"popularity\"] = df[\"popularity_category\"]\n",
    "        df = df.drop(columns=[\"popularity_category\"])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = preprocessing(\n",
    "        df,\n",
    "        use_title_track=True,\n",
    "        acoustic_features=acoustic_features,\n",
    "        mode=mode,\n",
    "    )\n",
    "\n",
    "    # Move the data to GPU if possible\n",
    "    logger.info(\"XGB Classifier...\")\n",
    "    model_xgb_cls = train_model_xgb_cls(X_train, y_train)\n",
    "    y_pred = evaluate_model(model_xgb_cls, X_test, y_test)\n",
    "    logger.info(f\"{accuracy_score(y_test, y_pred):.3f}\")\n",
    "    logger.info(classification_report(y_test, y_pred))\n",
    "\n",
    "    # logger.info(\"XGB Regressor...\")\n",
    "    # model_xgb = train_model_xgb(X_train, y_train)\n",
    "    # y_pred = evaluate_model(model_xgb, X_test, y_test)\n",
    "    # logger.info(f\"{accuracy_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "    logger.info(\"MLP Classifier...\")\n",
    "    model_mlp_cls = train_model_mlp_cls(X_train, y_train)\n",
    "    y_pred = evaluate_model(model_mlp_cls, X_test, y_test)\n",
    "    logger.info(f\"{accuracy_score(y_test, y_pred):.3f}\")\n",
    "    logger.info(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # logger.info(\"MLP Regressor...\")\n",
    "    # model_mlp = train_model_mlp(X_train, y_train)\n",
    "    # y_pred = evaluate_model(model_mlp, X_test, y_test)\n",
    "    # logger.info(f\"{accuracy_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "    logger.info(\"Random Forest...\")\n",
    "    model_random_forest = train_model_random_forest(X_train, y_train)\n",
    "    y_pred = evaluate_model(model_random_forest, X_test, y_test)\n",
    "    logger.info(f\"{accuracy_score(y_test, y_pred):.3f}\")\n",
    "    logger.info(classification_report(y_test, y_pred))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
